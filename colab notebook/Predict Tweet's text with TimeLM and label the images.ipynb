{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copia di Predict Tweet's text with TimeLM and label the images.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Predict Tweet's text with TimeLM\n","\n","This notebook contains the code to:\n","*   Predict the tweet's text with the [TimeLM model](https://github.com/cardiffnlp/timelms).\n","*   Compare the statistics of the B-T4SA 1.0 and of the B-T4SA 1.0 updated. It is used to create the confusion matrix which is present in the documentation.\n","\n","\n","\n"],"metadata":{"id":"zbOcGYnq2N8z"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"YrSNscWJVMvA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659199226595,"user_tz":-120,"elapsed":58647,"user":{"displayName":"ALESSIO SERRA","userId":"10572653186885782029"}},"outputId":"67f0e487-ec52-43e1-ff29-8559a3a233df"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.7 MB 8.0 MB/s \n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101 kB 8.1 MB/s \n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 596 kB 42.8 MB/s \n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.6 MB 36.0 MB/s \n","\u001b[?25h"]}],"source":["# dataset import\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","!pip -q install transformers\n","\n","import os\n","import sys\n","import torch\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","from scipy.special import softmax\n","from IPython.display import display\n","from transformers import AutoTokenizer, AutoConfig\n","from transformers import AutoModelForSequenceClassification"]},{"cell_type":"code","source":["MODEL = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n","BASE_DIR = \"/content/drive/MyDrive/Thesis/\"\n","DATASET_DIR = BASE_DIR + \"dataset/t4sa_2.0/\"\n","NEW_PREDICTION_DIR = DATASET_DIR + \"labeling/\"\n","PREDICTION_DIR = BASE_DIR + \"predictions/\"\n","\n","# Utility mappers to switch different labeling modality\n","class_mapper = {\"Negative\":0, \"Neutral\":1, \"Positive\": 2}"],"metadata":{"id":"dKQcyRyIaoqo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Predict text emotion"],"metadata":{"id":"2xwXbcKzI_Bb"}},{"cell_type":"code","source":["def preprocess(text):\n","  ''' Preprocess text (username and link placeholders)'''\n","  new_text = []\n","  for t in text.split(\" \"):\n","      t = '@user' if t.startswith('@') and len(t) > 1 else t  # some simple preprocessing to remove useless information,\n","      t = 'http' if t.startswith('http') else t               # which are just noise\n","      new_text.append(t)\n","  return \" \".join(new_text)\n"],"metadata":{"id":"ubhpURMgnXBu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# set the device on which computation is performed\n","print(torch.cuda.is_available())\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AATxDv0X8p1i","executionInfo":{"status":"ok","timestamp":1659199226597,"user_tz":-120,"elapsed":9,"user":{"displayName":"ALESSIO SERRA","userId":"10572653186885782029"}},"outputId":"3ec497c5-eb77-4d67-ca01-51d5b9643616"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["False\n","cpu\n"]}]},{"cell_type":"markdown","source":["## Predict B-T4SA 1.0"],"metadata":{"id":"atonYbnKS4v0"}},{"cell_type":"code","source":["# load the dataframe with the tweet's text\n","tweets_annot = pd.read_csv(DATASET_DIR + \"raw_tweets_text.csv\", delimiter=\",\")\n","id_all = tweets_annot[\"id\"].to_list()\n","text_all = tweets_annot[\"text\"].to_list()\n","\n","# load the dataframe with the image path and the assigned label (using previous text classifier)\n","bt4sa = pd.read_csv(DATASET_DIR + \"original_text_predictions/b-t4sa_all.txt\", names=[\"path\", \"label\"], delimiter=\" \", header=None)\n","id_bt4sa = bt4sa['path'].to_list()\n","\n","# i want to get only the ID to filter the tweets that are not present in B-T4SA\n","for i in range(len(id_bt4sa)):\n","  id_bt4sa[i] = int(id_bt4sa[i][11:29])  # I just take the ID, which is contained within the index [11, 29) of the image path\n","\n","# I want to remove duplicates since there are multiple images related to the same tweets, so identical ID in the list\n","id_bt4sa_filtered = set(id_bt4sa)   \n","\n","# find the intersection between text and bt4sa\n","intersection = [value for value in id_all if value in id_bt4sa_filtered]   "],"metadata":{"id":"SwelgcaKn1AN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# I build a dictionary with (ID, Text) items for each element in b-t4sa \n","id_bt4sa = []\n","text_bt4sa = []\n","\n","for i in range(len(id_all)):\n","  if id_all[i] in id_bt4sa_filtered:\n","    id_bt4sa.append(id_all[i])\n","    text_bt4sa.append(text_all[i])"],"metadata":{"id":"xnIJH9To6a9g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Sanity check to verify that are present all the text related to the images in b-t4sa\n","assert len(intersection) == len(id_bt4sa_filtered)\n","\n","print(len(intersection))\n","\n","print(len(id_bt4sa))\n","dict_tweet = dict(zip(id_bt4sa, text_bt4sa))\n","dict_all_tweet =  dict(zip(id_all, text_all))\n","\n","intersect_dict = dict(dict_all_tweet.items() & dict_tweet.items())  \n","\n","assert intersect_dict == dict_tweet\n","print(len(intersect_dict), len(dict_tweet), len(dict_all_tweet))"],"metadata":{"id":"hvPUOmNszCJB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get the tokenizer of the TimeLM model\n","tokenizer = AutoTokenizer.from_pretrained(MODEL)\n","\n","# Get the configuration of the TimeLM model\n","config = AutoConfig.from_pretrained(MODEL)\n","\n","# Get the TimeLM model\n","model = AutoModelForSequenceClassification.from_pretrained(MODEL).to(device)"],"metadata":{"id":"4SOPt-GyaBoq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# initialize the data structures that holds the predictions\n","id_preds = []\n","neg_preds = []\n","neu_preds = []\n","pos_preds = []\n","\n","# Counter for the Backup\n","counter=0\n","\n","for i in tqdm(range(len(text_bt4sa))):  \n","  id = id_bt4sa[i]\n","  text = text_bt4sa[i]\n","\n","  if dict_tweet[id] != text:  # Check that everything is correct (can be avoided)\n","    print(\"ERORR!\")\n","    break\n","\n","  # Preprocess the tweet\n","  text = preprocess(text)\n","\n","  # Tokenize the text\n","  encoded_input = tokenizer(text, return_tensors='pt').to(device)\n","  \n","  # Get the logits produced by the model\n","  output = model(**encoded_input)\n","\n","  # Get a probability distribution from the logits\n","  scores = output[0][0].detach().cpu().numpy()\n","  scores = softmax(scores)\n","\n","  id_preds.append(id) \n","  neg_preds.append(scores[0])\n","  neu_preds.append(scores[1])\n","  pos_preds.append(scores[2])\n","\n","  # Every 50 tweets I save a backup \n","  if i%50==0 and i != 0:\n","    new_predictions = pd.DataFrame({'TWID': id_preds, 'NEG': neg_preds, 'NEU': neu_preds, 'POS': pos_preds})\n","    new_predictions.to_csv(\"bt4sa_predictions_backup_\" + str(counter) + \".tsv\", sep=\"\\t\", index = False)\n","    counter+=1\n","\n","# Save the dataframe with all the predictions\n","new_predictions = pd.DataFrame({'TWID': id_preds, 'NEG': neg_preds, 'NEU': neu_preds, 'POS': pos_preds})\n","new_predictions.to_csv(DATASET_DIR + \"bt4sa_predictions_con_overlap.tsv\", sep=\"\\t\", index = False)"],"metadata":{"id":"nX2s0FBRVgIJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Predict T4SA 2.0"],"metadata":{"id":"LdQSO1QvTAoV"}},{"cell_type":"code","source":["tweets_annot = pd.read_csv(DATASET_DIR + \"raw_tweets_text_final.csv\", on_bad_lines='skip')\n","display(tweets_annot)\n","id_all = tweets_annot[\"id\"].to_list()\n","text_all = tweets_annot[\"text\"].to_list()\n","\n","dict_tweet = dict(zip(id_all, text_all))"],"metadata":{"id":"z7cNmh4wdKlN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get the tokenizer of the TimeLM model\n","tokenizer = AutoTokenizer.from_pretrained(MODEL)\n","\n","# Get the configuration of the TimeLM model\n","config = AutoConfig.from_pretrained(MODEL)\n","\n","# Get the TimeLM model and move it to the GPU\n","model = AutoModelForSequenceClassification.from_pretrained(MODEL).to(device)"],"metadata":{"id":"AOD6WVhdT_Vn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# initialize the data structures that holds the predictions\n","id_preds = []\n","neg_preds = []\n","neu_preds = []\n","pos_preds = []\n","\n","# Counter for the Backup\n","counter=0\n","\n","for i in tqdm(range(len(text_all))[2500000:]):  \n","  id = id_all[i]\n","  text = text_all[i]\n","  try:\n","    if dict_tweet[id] != text:  # Check that everything is correct (can be avoided)\n","      print(\"ERORR! WIth text\", dict_tweet[id])\n","      raise Exception\n","\n","    # Preprocess the tweet\n","    text = preprocess(text)\n","\n","    # Tokenize the text\n","    encoded_input = tokenizer(text, return_tensors='pt').to(device)\n","\n","\n","  # Get the logits produced by the model\n","    output = model(**encoded_input)\n","\n","    # Get a probability distribution from the logits\n","    scores = output[0][0].detach().cpu().numpy()\n","    scores = softmax(scores)\n","\n","    id_preds.append(id) \n","    neg_preds.append(scores[0])\n","    neu_preds.append(scores[1])\n","    pos_preds.append(scores[2])\n","\n","  except Exception as ex:\n","    exc_info = sys.exc_info()\n","    print(exc_info)\n","    id_preds.append(id)\n","    neg_preds.append(-1)\n","    neu_preds.append(-1)\n","    pos_preds.append(-1)\n","\n","  # Every 50 tweets I save a backup \n","  if i%50000==0 and i != 2500000:\n","    print(f\"Saving backup after {i} images...\")\n","    new_predictions = pd.DataFrame({'TWID': id_preds, 'NEG': neg_preds, 'NEU': neu_preds, 'POS': pos_preds})\n","    new_predictions.to_csv(NEW_PREDICTION_DIR + \"t4sa2.0_predictions_latest_backup_test_\" + str(counter) + \".tsv\", sep=\"\\t\", index = False)\n","    counter+=1\n","\n","# Save the dataframe with all the predictions\n","new_predictions = pd.DataFrame({'TWID': id_preds, 'NEG': neg_preds, 'NEU': neu_preds, 'POS': pos_preds})\n","new_predictions.to_csv(NEW_PREDICTION_DIR + \"bt4sa_predictions_latest_test_con_overlap.tsv\", sep=\"\\t\", index = False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RzjnNqOrTD3I","executionInfo":{"status":"ok","timestamp":1658491462321,"user_tz":-120,"elapsed":6632,"user":{"displayName":"ALESSIA GRECO","userId":"04852991982184667528"}},"outputId":"3652c7c0-2ee0-4767-9a9e-8587f686734b"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":[" 10%|â–ˆ         | 49992/479630 [10:25<1:28:31, 80.88it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Saving backup after 2550000 images...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":[" 21%|â–ˆâ–ˆ        | 100000/479630 [20:44<1:14:59, 84.38it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Saving backup after 2600000 images...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":[" 31%|â–ˆâ–ˆâ–ˆâ–      | 149996/479630 [30:50<1:05:37, 83.72it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Saving backup after 2650000 images...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":[" 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 199999/479630 [41:17<57:12, 81.47it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Saving backup after 2700000 images...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":[" 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 249997/479630 [51:50<52:06, 73.46it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Saving backup after 2750000 images...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":[" 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 299997/479630 [1:02:22<37:09, 80.59it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Saving backup after 2800000 images...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":[" 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 349993/479630 [1:12:48<26:24, 81.84it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Saving backup after 2850000 images...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":[" 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 399996/479630 [1:23:15<15:50, 83.80it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Saving backup after 2900000 images...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":[" 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 449992/479630 [1:33:20<05:49, 84.77it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Saving backup after 2950000 images...\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 479630/479630 [1:39:19<00:00, 80.48it/s]\n"]}]},{"cell_type":"markdown","source":["# Create files with predictions"],"metadata":{"id":"_a68fRhTcvlW"}},{"cell_type":"markdown","source":["## Merge multiple files"],"metadata":{"id":"vSyolxo9LN7p"}},{"cell_type":"code","source":["# Merge different backup files\n","file_list = [f for f in os.listdir(NEW_PREDICTION_DIR) if os.path.isfile(os.path.join(NEW_PREDICTION_DIR, f))]\n","print(f\"Merging {len(file_list)} files...\")\n","\n","df_list = []\n","for df in file_list:\n","  df_list.append(pd.read_csv(os.path.join(NEW_PREDICTION_DIR, df), delimiter=\"\\t\"))\n","\n","# Concat all on the 0 axis\n","tweets_preds_all = pd.concat(df_list, axis=0)"],"metadata":{"id":"cMkh_qxcJZxJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658505530382,"user_tz":-120,"elapsed":18828,"user":{"displayName":"Alessio Serra","userId":"13394898951603938860"}},"outputId":"e062d14b-2dac-440c-b0f2-b2dd71b5f197"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Merging 35 files...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n","  exec(code_obj, self.user_global_ns, self.user_ns)\n"]}]},{"cell_type":"code","source":["# Merging from multiple files\n","print(\"Merged size:\", len(tweets_preds_all))\n","\n","# Cast the TWID column in string\n","tweets_preds_all[\"TWID\"] = tweets_preds_all[\"TWID\"].apply(str) \n","\n","# Files may contain many duplicates with different precision in the predictions, so i filter just to keep only one prediction per TWID\n","tweets_preds_all.drop_duplicates(subset=\"TWID\", keep=\"first\", inplace=True)\n","print(\"Size after duplicate removal:\", len(tweets_preds_all))\n","\n","# Start the cleaning\n","\n","# Remove NaN values\n","tweets_preds_all.dropna(inplace=True)\n","\n","# Remove all the tweets that were collected after 30th of June (they all starts with 15427)\n","tweets_preds_all = tweets_preds_all[~tweets_preds_all['TWID'].str.lower().str.startswith(\"15427\")]\n","\n","# Remove all the bad TWID if any\n","tweets_preds_all = tweets_preds_all[tweets_preds_all['TWID'].str.lower().str.startswith(\"1\")]\n","\n","# Sort by TWID (coincide with sort in chronological order)\n","tweets_preds_all.sort_values(\"TWID\", inplace=True)\n","\n","# Reset the index\n","tweets_preds_all.reset_index(inplace=True, drop=True)\n","already_inferred_tweets = tweets_preds_all[\"TWID\"].tolist()\n","print(\"Size after NaN removal:\", len(tweets_preds_all))\n","print(\"Number of already labeled tweets:\", len(already_inferred_tweets))\n","\n","tweets_annot = pd.read_csv(DATASET_DIR + \"raw_tweets_text_final.csv\", lineterminator='\\n')\n","\n","tweets_annot[\"id\"] = tweets_annot[\"id\"].apply(str) \n","total_tweets = tweets_annot[\"id\"].tolist()\n","print(\"Size of total tweets:\", len(total_tweets))\n","\n","# Counting the number of tweets that are not labeled\n","remaining_tweets = list(set(total_tweets) - set(already_inferred_tweets))\n","print(\"Remaining tweets to label:\", len(remaining_tweets))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L5ZDU4a2kx-N","executionInfo":{"status":"ok","timestamp":1658505579656,"user_tz":-120,"elapsed":32426,"user":{"displayName":"Alessio Serra","userId":"13394898951603938860"}},"outputId":"55ac280b-e6b4-4c04-cb0a-80951669c136"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Merged size: 11886424\n","Size after duplicate removal: 2979626\n","Size after NaN removal: 2970114\n","Number of already labeled tweets: 2970114\n","Size of total tweets: 2970114\n","Remaining tweets to label: 0\n"]}]},{"cell_type":"code","source":["display(pd.merge(tweets_preds_all, tweets_annot, how='inner',right_on=['id'], left_on=['TWID']).drop('id', axis=1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"Q4FmtS6gfgF_","executionInfo":{"status":"ok","timestamp":1658505584376,"user_tz":-120,"elapsed":3361,"user":{"displayName":"Alessio Serra","userId":"13394898951603938860"}},"outputId":"ab081cda-eb54-441e-e3aa-fa5170071b8f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["                        TWID       NEG       NEU       POS  \\\n","0        1510943913678450696  0.003139  0.065183  0.931678   \n","1        1510943913686691848  0.003431  0.055094  0.941475   \n","2        1510943922100781057  0.005960  0.062065  0.931975   \n","3        1510943947245371393  0.017227  0.494703  0.488071   \n","4        1510943951443820547  0.045747  0.912404  0.041849   \n","...                      ...       ...       ...       ...   \n","2970109  1542699945584922624  0.005857  0.314748  0.679395   \n","2970110  1542699962345086977  0.008627  0.076977  0.914396   \n","2970111  1542699970750337024  0.005689  0.038025  0.956286   \n","2970112  1542699974944645121  0.016026  0.920362  0.063612   \n","2970113  1542699987523342341  0.121603  0.632605  0.245792   \n","\n","                                                      text  \n","0        never forget when Kanye and Jay Z performed N*...  \n","1        When it comes to style in warm day, less reall...  \n","2        Grey Suit is so beautiful â˜ºðŸ’•\\n\\nhttps://t.co/n...  \n","3        A little D heavy..\\n\\nZach Tom will be an athl...  \n","4        .@SarahLGates1\\n\\nIslam &amp; Christianity use...  \n","...                                                    ...  \n","2970109  Watch the sunset with me. \\n\\nLine art by @gab...  \n","2970110  D'instinct j'ai lu \"RM is the best leader\" ðŸ˜‚ h...  \n","2970111  Imam Ali and his wife Fatima are the most loya...  \n","2970112  à¼ºà½».RECOMMENDED ! \\nâ”€â”€â”€â”€âž¤\\n   âœ¦ @DaniellaPutri_...  \n","2970113  Pakistan used Article 370 as a tool to spread ...  \n","\n","[2970114 rows x 5 columns]"],"text/html":["\n","  <div id=\"df-30276159-a7db-400a-8ffd-349f5c937d85\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>TWID</th>\n","      <th>NEG</th>\n","      <th>NEU</th>\n","      <th>POS</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1510943913678450696</td>\n","      <td>0.003139</td>\n","      <td>0.065183</td>\n","      <td>0.931678</td>\n","      <td>never forget when Kanye and Jay Z performed N*...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1510943913686691848</td>\n","      <td>0.003431</td>\n","      <td>0.055094</td>\n","      <td>0.941475</td>\n","      <td>When it comes to style in warm day, less reall...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1510943922100781057</td>\n","      <td>0.005960</td>\n","      <td>0.062065</td>\n","      <td>0.931975</td>\n","      <td>Grey Suit is so beautiful â˜ºðŸ’•\\n\\nhttps://t.co/n...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1510943947245371393</td>\n","      <td>0.017227</td>\n","      <td>0.494703</td>\n","      <td>0.488071</td>\n","      <td>A little D heavy..\\n\\nZach Tom will be an athl...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1510943951443820547</td>\n","      <td>0.045747</td>\n","      <td>0.912404</td>\n","      <td>0.041849</td>\n","      <td>.@SarahLGates1\\n\\nIslam &amp;amp; Christianity use...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2970109</th>\n","      <td>1542699945584922624</td>\n","      <td>0.005857</td>\n","      <td>0.314748</td>\n","      <td>0.679395</td>\n","      <td>Watch the sunset with me. \\n\\nLine art by @gab...</td>\n","    </tr>\n","    <tr>\n","      <th>2970110</th>\n","      <td>1542699962345086977</td>\n","      <td>0.008627</td>\n","      <td>0.076977</td>\n","      <td>0.914396</td>\n","      <td>D'instinct j'ai lu \"RM is the best leader\" ðŸ˜‚ h...</td>\n","    </tr>\n","    <tr>\n","      <th>2970111</th>\n","      <td>1542699970750337024</td>\n","      <td>0.005689</td>\n","      <td>0.038025</td>\n","      <td>0.956286</td>\n","      <td>Imam Ali and his wife Fatima are the most loya...</td>\n","    </tr>\n","    <tr>\n","      <th>2970112</th>\n","      <td>1542699974944645121</td>\n","      <td>0.016026</td>\n","      <td>0.920362</td>\n","      <td>0.063612</td>\n","      <td>à¼ºà½».RECOMMENDED ! \\nâ”€â”€â”€â”€âž¤\\n   âœ¦ @DaniellaPutri_...</td>\n","    </tr>\n","    <tr>\n","      <th>2970113</th>\n","      <td>1542699987523342341</td>\n","      <td>0.121603</td>\n","      <td>0.632605</td>\n","      <td>0.245792</td>\n","      <td>Pakistan used Article 370 as a tool to spread ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2970114 rows Ã— 5 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-30276159-a7db-400a-8ffd-349f5c937d85')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-30276159-a7db-400a-8ffd-349f5c937d85 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-30276159-a7db-400a-8ffd-349f5c937d85');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["# Save the dataframe with all the predictions\n","tweets_preds_all.to_csv(DATASET_DIR + \"t4sa2.0_text_prediction_final.csv\", index=False)\n","pd.read_csv(DATASET_DIR + \"t4sa2.0_text_prediction_final.csv\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":480},"id":"eNCjNsTmlOHe","executionInfo":{"status":"ok","timestamp":1658505615104,"user_tz":-120,"elapsed":2979,"user":{"displayName":"Alessio Serra","userId":"13394898951603938860"}},"outputId":"cb39f909-14ac-4b7c-a604-c7e550edf29c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n","  exec(code_obj, self.user_global_ns, self.user_ns)\n"]},{"output_type":"execute_result","data":{"text/plain":["                        TWID       NEG       NEU       POS\n","0        1510943913678450696  0.003139  0.065183  0.931678\n","1        1510943913686691848  0.003431  0.055094  0.941475\n","2        1510943922100781057  0.005960  0.062065  0.931975\n","3        1510943947245371393  0.017227  0.494703  0.488071\n","4        1510943951443820547  0.045747  0.912404  0.041849\n","...                      ...       ...       ...       ...\n","2970109  1542699945584922624  0.005857  0.314748  0.679395\n","2970110  1542699962345086977  0.008627  0.076977  0.914396\n","2970111  1542699970750337024  0.005689  0.038025  0.956286\n","2970112  1542699974944645121  0.016026  0.920362  0.063612\n","2970113  1542699987523342341  0.121603  0.632605  0.245792\n","\n","[2970114 rows x 4 columns]"],"text/html":["\n","  <div id=\"df-dc7fd961-38fc-4707-8983-d05205560851\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>TWID</th>\n","      <th>NEG</th>\n","      <th>NEU</th>\n","      <th>POS</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1510943913678450696</td>\n","      <td>0.003139</td>\n","      <td>0.065183</td>\n","      <td>0.931678</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1510943913686691848</td>\n","      <td>0.003431</td>\n","      <td>0.055094</td>\n","      <td>0.941475</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1510943922100781057</td>\n","      <td>0.005960</td>\n","      <td>0.062065</td>\n","      <td>0.931975</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1510943947245371393</td>\n","      <td>0.017227</td>\n","      <td>0.494703</td>\n","      <td>0.488071</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1510943951443820547</td>\n","      <td>0.045747</td>\n","      <td>0.912404</td>\n","      <td>0.041849</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2970109</th>\n","      <td>1542699945584922624</td>\n","      <td>0.005857</td>\n","      <td>0.314748</td>\n","      <td>0.679395</td>\n","    </tr>\n","    <tr>\n","      <th>2970110</th>\n","      <td>1542699962345086977</td>\n","      <td>0.008627</td>\n","      <td>0.076977</td>\n","      <td>0.914396</td>\n","    </tr>\n","    <tr>\n","      <th>2970111</th>\n","      <td>1542699970750337024</td>\n","      <td>0.005689</td>\n","      <td>0.038025</td>\n","      <td>0.956286</td>\n","    </tr>\n","    <tr>\n","      <th>2970112</th>\n","      <td>1542699974944645121</td>\n","      <td>0.016026</td>\n","      <td>0.920362</td>\n","      <td>0.063612</td>\n","    </tr>\n","    <tr>\n","      <th>2970113</th>\n","      <td>1542699987523342341</td>\n","      <td>0.121603</td>\n","      <td>0.632605</td>\n","      <td>0.245792</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2970114 rows Ã— 4 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc7fd961-38fc-4707-8983-d05205560851')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-dc7fd961-38fc-4707-8983-d05205560851 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-dc7fd961-38fc-4707-8983-d05205560851');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["# Analysis of two predictions"],"metadata":{"id":"TSQ6naREDg5C"}},{"cell_type":"code","source":["def print_length_statistics(annot):\n","  for class_ in classes_mapper.keys():\n","    print(f\"Length of {class_}: {len(annot[annot['label'] == class_mapper[class_]]):,}\")"],"metadata":{"id":"smIQScXc_zOE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the dataframe with the old and the new predictions\n","new_predictions = pd.read_csv(DATASET_DIR + \"new_text_predictions/bt4sa/b-t4sa_all.tsv\", delimiter=\"\\t\")\n","original_predictions = pd.read_csv(DATASET_DIR + \"original_text_predictions/b-t4sa_all.txt\", names=[\"path\", \"label\"], delimiter=\" \", header=None)\n","\n","# Store in an array all the new and the old labels\n","new_label = new_predictions['label'].to_list()\n","original_label = original_predictions['label'].to_list()"],"metadata":{"id":"a5bwIulRDoCE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Print statistics of original predictions:\")\n","print_length_statistics(original_predictions)\n","\n","print(\"\\n\\nPrint statistics of updated predictions:\")\n","print_length_statistics(new_predictions)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5qgZ_ioe--72","executionInfo":{"status":"ok","timestamp":1659199455985,"user_tz":-120,"elapsed":278,"user":{"displayName":"ALESSIO SERRA","userId":"10572653186885782029"}},"outputId":"e5e1b1ae-dabf-4e86-dc62-c82ae944d002"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Print statistics of original predictions:\n","Length of Negative: 156,862\n","Length of Neutral: 156,862\n","Length of Positive: 156,862\n","\n","\n","Print statistics of updated predictions:\n","Length of Negative: 95,272\n","Length of Neutral: 182,295\n","Length of Positive: 193,019\n"]}]},{"cell_type":"code","source":["# the base polarity considered is the original one\n","\n","# Initialization of data structure to count the difference\n","count_diff = 0\n","count_diff_class = [[0, 0, 0],\n","                    [0, 0, 0],\n","                    [0, 0, 0]]   # 0 for NEG, 1 for NEU, 2 for POS\n","\n","                    #Negative\n","                    #Neutral\n","                    #Positive\n","\n","# Compare all the new labels with the old ones\n","for i in range(len(new_label)):\n","  if new_label[i] != original_label[i]:\n","    count_diff += 1\n","    count_diff_class[original_label[i]][new_label[i]] += 1  #in this way i keep track of the change\n","  else:\n","    count_diff_class[original_label[i]][new_label[i]] += 1 \n","\n","# Print results obtained\n","print(\"Total differences:\", count_diff)\n","print(\"Total equal:\", len(original_label) - count_diff)\n","print(f\"Percentage changed: {int(count_diff/len(original_label) * 100)}%\\n\")\n","\n","print(\"#Negative --> Positive:\", count_diff_class[0][2])\n","print(\"#Negative --> Neutral:\", count_diff_class[0][1], '\\n')\n","\n","print(\"#Neutral --> Positive:\", count_diff_class[1][2])\n","print(\"#Neutral --> Negative:\", count_diff_class[1][0], '\\n')\n","\n","print(\"#Positive --> Negative:\", count_diff_class[2][0])\n","print(\"#Positive --> Neutral:\", count_diff_class[2][1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UhzvBf_9g5z1","executionInfo":{"status":"ok","timestamp":1659199541427,"user_tz":-120,"elapsed":292,"user":{"displayName":"ALESSIO SERRA","userId":"10572653186885782029"}},"outputId":"391ee9fe-24c9-48b7-fc56-bceb76b8036d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total differences: 105044\n","Total equal: 365542\n","Percentage changed: 22%\n","\n","#Negative --> Positive: 20673\n","#Negative --> Neutral: 46713 \n","\n","#Neutral --> Positive: 24832\n","#Neutral --> Negative: 3478 \n","\n","#Positive --> Negative: 2318\n","#Positive --> Neutral: 7030\n","[[89476, 46713, 20673], [3478, 128552, 24832], [2318, 7030, 147514]]\n"]}]}]}